{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.023479,"end_time":"2021-07-16T17:41:26.264343","exception":false,"start_time":"2021-07-16T17:41:26.240864","status":"completed"},"tags":[]},"source":["<h1>BM25 - <i>Best Match 25</i></h1> \n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-02-23T03:58:14.233800Z","iopub.status.busy":"2023-02-23T03:58:14.233359Z","iopub.status.idle":"2023-02-23T03:58:16.000511Z","shell.execute_reply":"2023-02-23T03:58:15.999642Z","shell.execute_reply.started":"2023-02-23T03:58:14.233698Z"},"papermill":{"duration":1.752359,"end_time":"2021-07-16T17:41:28.084744","exception":false,"start_time":"2021-07-16T17:41:26.332385","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["## Library imports\n","import numpy as np \n","import pandas as pd\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","import os, glob, re, sys, random, unicodedata, collections\n","from tqdm import tqdm\n","from functools import reduce\n","import nltk\n","from collections import Counter\n","\n","from nltk.corpus import stopwords\n","from nltk.stem import RSLPStemmer\n","from nltk.tokenize import sent_tokenize , word_tokenize\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.046211,"end_time":"2021-07-16T17:41:55.253069","exception":false,"start_time":"2021-07-16T17:41:55.206858","status":"completed"},"tags":[]},"source":["# Evaluating BM25\n","\n","There are several metrics to evaluate IR systems. The evaluation process consists of \"firing\" a set of queries \"against\" the IR System and compare the returned documents with the answers annotated in relevance mapping. Some metrics use the orders of returned documents, but others don't. In some metrics we define a cut in the number of documents returned (i.e. top 10 documents only). \n","\n","We will use [MRR@10 (Mean Reciprocal Rank)](https://en.wikipedia.org/wiki/Mean_reciprocal_rank), a metric which takes into account only the position of the first relevant document returned into the first 10 documents by each query. MS Marco benchmark also uses this metric, but it is calculated with 100 first returned results.\n"]},{"cell_type":"markdown","metadata":{},"source":["The code above will receive a boolean relevance results vector and return the MRR@10."]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-02-23T03:58:32.083768Z","iopub.status.busy":"2023-02-23T03:58:32.081809Z","iopub.status.idle":"2023-02-23T03:58:32.097714Z","shell.execute_reply":"2023-02-23T03:58:32.096816Z","shell.execute_reply.started":"2023-02-23T03:58:32.083720Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.611111111111111"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["##Source: https://gist.github.com/bwhite/3726239\n","def mean_reciprocal_rank(bool_results, k=10):\n","    \"\"\"Score is reciprocal of the rank of the first relevant item\n","    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n","    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n","    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n","    >>> mean_reciprocal_rank(rs)\n","    0.61111111111111105\n","\n","    Args:\n","        rs: Iterator of relevance scores (list or numpy) in rank order\n","            (first element is the first item)\n","    Returns:\n","        Mean reciprocal rank\n","    \"\"\"\n","    bool_results = (np.atleast_1d(r[:k]).nonzero()[0] for r in bool_results)\n","    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in bool_results])\n","\n","mean_reciprocal_rank([[0, 0, 1], [0, 1, 0], [1, 0, 0]])"]},{"cell_type":"code","execution_count":15,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-02-23T03:58:32.104415Z","iopub.status.busy":"2023-02-23T03:58:32.102025Z","iopub.status.idle":"2023-02-23T04:01:02.572655Z","shell.execute_reply":"2023-02-23T04:01:02.568986Z","shell.execute_reply.started":"2023-02-23T03:58:32.104362Z"},"papermill":{"duration":9.234171,"end_time":"2021-07-16T17:42:04.534024","exception":false,"start_time":"2021-07-16T17:41:55.299853","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rank_bm25 in /home/cristiano/.local/lib/python3.8/site-packages (0.2.2)\n","Requirement already satisfied: numpy in /home/cristiano/.local/lib/python3.8/site-packages (from rank_bm25) (1.19.5)\n"]}],"source":["!pip3 install rank_bm25\n","from rank_bm25 import BM25Okapi"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load and process CISI dataset"]},{"cell_type":"code","execution_count":16,"metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-02-23T04:01:02.575745Z","iopub.status.idle":"2023-02-23T04:01:02.578196Z"},"trusted":true},"outputs":[],"source":["### Processing DOCUMENTS\n","doc_set = {}\n","doc_id = \"\"\n","doc_text = \"\"\n","with open('cisi/CISI.ALL') as f:\n","    lines = \"\"\n","    for l in f.readlines():\n","        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n","    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n","doc_count = 0\n","for l in lines:\n","    if l.startswith(\".I\"):\n","        doc_id = int(l.split(\" \")[1].strip())-1\n","    elif l.startswith(\".X\"):\n","        doc_set[doc_id] = doc_text.lstrip(\" \")\n","        doc_id = \"\"\n","        doc_text = \"\"\n","    else:\n","        doc_text += l.strip()[3:] + \" \" # The first 3 characters of a line can be ignored.    \n","\n","        \n","### Processing QUERIES\n","with open('cisi/CISI.QRY') as f:\n","    lines = \"\"\n","    for l in f.readlines():\n","        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n","    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n","    \n","qry_set = {}\n","qry_id = \"\"\n","for l in lines:\n","    if l.startswith(\".I\"):\n","        qry_id = int(l.split(\" \")[1].strip()) -1\n","    elif l.startswith(\".W\"):\n","        qry_set[qry_id] = l.strip()[3:]\n","        qry_id = \"\"\n","\n","### Processing QRELS\n","rel_set = {}\n","with open('cisi/CISI.REL') as f:\n","    for l in f.readlines():\n","        qry_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]) -1\n","        doc_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1])-1\n","        if qry_id in rel_set:\n","            rel_set[qry_id].append(doc_id)\n","        else:\n","            rel_set[qry_id] = []\n","            rel_set[qry_id].append(doc_id)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:01:02.581880Z","iopub.status.idle":"2023-02-23T04:01:02.583950Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Read 1460 documents, 112 queries and 76 mappings from CISI dataset\n","Average 40.97 and 1 min number of relevant documents by query \n","Queries without relevant documents:  [ 35  37  39  46  47  50  52  58  59  62  63  67  69  71  72  73  74  76\n","  77  79  82  84  85  86  87  88  90  92  93 102 104 105 106 107 109 111]\n"]}],"source":["## Here we check some statistics and info of CISI dataset\n","\n","print('Read %s documents, %s queries and %s mappings from CISI dataset' % \n","      (len(doc_set), len(qry_set), len(rel_set)))\n","\n","number_of_rel_docs = [len(value) for key, value in rel_set.items()]\n","print('Average %.2f and %d min number of relevant documents by query ' % \n","      (np.mean(number_of_rel_docs), np.min(number_of_rel_docs)))\n","\n","print('Queries without relevant documents: ', \n","      np.setdiff1d(list(qry_set.keys()),list(rel_set.keys())))"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-07-16T22:49:46.370422Z","iopub.status.busy":"2021-07-16T22:49:46.370047Z","iopub.status.idle":"2021-07-16T22:49:46.376003Z","shell.execute_reply":"2021-07-16T22:49:46.37497Z","shell.execute_reply.started":"2021-07-16T22:49:46.370393Z"}},"source":["Below there's a sample of a pair query and a document relevant to it in the dataset."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:01:02.587314Z","iopub.status.idle":"2023-02-23T04:01:02.589341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Query ID 14 ==> How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?\n","Documents relevants to Query ID 14 [17, 26, 35, 48, 55, 58, 66, 73, 82, 125, 157, 163, 166, 191, 213, 221, 222, 249, 280, 291, 294, 298, 306, 330, 335, 337, 347, 364, 365, 366, 367, 371, 380, 445, 457, 464, 465, 481, 489, 490, 494, 496, 506, 519, 527, 590, 593, 622, 628, 638, 689, 719, 722, 723, 726, 727, 730, 778, 821, 833, 838, 847, 848, 864, 871, 896, 1099, 1160, 1247, 1304, 1352, 1357, 1362, 1365, 1367, 1370, 1371, 1373, 1374, 1375, 1376, 1409]\n","Document ID 48 ==> Adaptive Information Dissemination Sage, C.R. Anderson, R.R. Fitzwater, D.R. Computer dissemination of information offers significant advantages over manual dissemination because the computer can use strategies that are impractical and in some cases impossible for a human.. This paper describes the Ames Laboratory Selective Dissemination of Information system with emphasis on the effectiveness of user feedback.. The system will accept any document, abstract, keyword, etc., in a KWIC or Science Citation Index Source format.. User profiles consist of words or word clusters each with an initially assigned significance value.. These values are used in making the decision to notify a user that he may be interested in a particular document.. According to responses, the significance values are increased or decreased and quickly attain an equilibrium which accurately describes the user's interests.. The system is economical compared to other existing SDI systems and human intervention is negligible except for adding and deleting profile entries.. \n"]}],"source":["random.seed(42)\n","idx = random.sample(rel_set.keys(),1)[0]\n","\n","print('Query ID %s ==>' % idx, qry_set[idx])\n","rel_docs = rel_set[idx]\n","print('Documents relevants to Query ID %s' % idx, rel_docs)\n","sample_document_idx = random.sample(rel_docs,1)[0]\n","print('Document ID %s ==>' % sample_document_idx, doc_set[sample_document_idx])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Index CISI dataset using BM25"]},{"cell_type":"markdown","metadata":{},"source":["In the code below we index each document from CISI without any preprocessing and get scores for one random query."]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:01:02.592605Z","iopub.status.idle":"2023-02-23T04:01:02.594659Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Query ==>  How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry? \n","Relevant documents IDs: ==>  [17, 26, 35, 48, 55, 58, 66, 73, 82, 125, 157, 163, 166, 191, 213, 221, 222, 249, 280, 291, 294, 298, 306, 330, 335, 337, 347, 364, 365, 366, 367, 371, 380, 445, 457, 464, 465, 481, 489, 490, 494, 496, 506, 519, 527, 590, 593, 622, 628, 638, 689, 719, 722, 723, 726, 727, 730, 778, 821, 833, 838, 847, 848, 864, 871, 896, 1099, 1160, 1247, 1304, 1352, 1357, 1362, 1365, 1367, 1370, 1371, 1373, 1374, 1375, 1376, 1409]\n","[13.84492303 12.72656528 17.02184487 ... 12.72737224 14.26660278\n"," 14.10298505] 1460 1460\n"]}],"source":["query = qry_set[idx] #get query text\n","rel_docs = rel_set[idx] #get relevant documents\n","\n","# Index all documents using BM25\n","corpus = list(doc_set.values())\n","tokenized_corpus = [doc.split(\" \") for doc in corpus]\n","bm25 = BM25Okapi(tokenized_corpus)\n","\n","# Process query and get scores for each indexed document using BM25\n","tokenized_query = query.split(\" \")\n","print('Query ==> ', query, '\\nRelevant documents IDs: ==> ', rel_docs)\n","scores = bm25.get_scores(tokenized_query)\n","print(scores, len(scores), len(doc_set))"]},{"cell_type":"markdown","metadata":{},"source":["Finally we sort documents by score, compare with hand annotated relevant documents from dataset and create a boolean mask of the results. With this boolean array we can calculate MRR@10."]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:01:02.597759Z","iopub.status.idle":"2023-02-23T04:01:02.598502Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 655  593  254  663  767  176  292  514  363  139   23  313 1026  460\n"," 1447 1236  825  326 1276   27]\n","[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","0.5\n"]}],"source":["## Argsort gives the indexes of values in increasing order, so we input with the negative values of scores\n","most_relevant_documents = np.argsort(-scores)\n","\n","print(most_relevant_documents[:20]) # printing first 20 most relevant results\n","\n","## Mask relevant documents with 0's and 1's according to query <-> document annotation\n","masked_relevance_results = np.zeros(most_relevant_documents.shape)\n","masked_relevance_results[rel_docs] = 1\n","sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n","\n","print(sorted_masked_relevance_results[:20]) #printing first 20 results: 1 is relevant 0 isn't\n","\n","# Calculate MRR@10\n","print(mean_reciprocal_rank([sorted_masked_relevance_results]))"]},{"cell_type":"markdown","metadata":{},"source":["Now we're ready to reproduce scores through all queries in dataset. First we'll create a function to return the masked results."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:01:02.599677Z","iopub.status.idle":"2023-02-23T04:01:02.604539Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["MRR@10 0.3146\n"]}],"source":["def results_from_query(qry_id, bm25):\n","    \"\"\"Return an ordered array of relevant documents returned by query_id\n","\n","    Args:\n","        qry_id (int): id of query on dataset\n","        bm25 (object): indexed corpus\n","\n","    Returns:\n","        boolean sorted relevance array of documents\n","    \"\"\"    \n","    query = qry_set[qry_id]\n","    rel_docs = []\n","    if qry_id in rel_set:\n","        rel_docs = rel_set[qry_id]\n","    tokenized_query = query.split(\" \")\n","    scores = bm25.get_scores(tokenized_query)\n","    most_relevant_documents = np.argsort(-scores)\n","    masked_relevance_results = np.zeros(most_relevant_documents.shape)\n","  \n","    masked_relevance_results[rel_docs] = 1\n","    sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n","    \n","    return sorted_masked_relevance_results\n","\n","\n","results = [results_from_query(qry_id, bm25) for qry_id in list(qry_set.keys())]\n","print('MRR@10 %.4f' % mean_reciprocal_rank(results))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Trying to improve results\n","\n","In this section we'll try to improve results through preprocessing our corpus and query using stemming, lowercase and removing stop words."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:01:02.605828Z","iopub.status.idle":"2023-02-23T04:01:02.606529Z"},"trusted":true},"outputs":[],"source":["# Instaciate objects from NLTK\n","stemmer = nltk.stem.PorterStemmer()\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","stop_words = nltk.corpus.stopwords.words('english')"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:01:02.607627Z","iopub.status.idle":"2023-02-23T04:01:02.608290Z"},"trusted":true},"outputs":[],"source":["def preprocess_string(txt, remove_stop=True, do_stem=True, to_lower=True):\n","    \"\"\"\n","    Return a preprocessed tokenized text.\n","    \n","    Args:\n","        txt (str): original text to process\n","        remove_stop (boolean): to remove or not stop words (common words)\n","        do_stem (boolean): to do or not stemming (suffixes and prefixes removal)\n","        to_lower (boolean): remove or not capital letters.\n","        \n","    Returns:\n","        Return a preprocessed tokenized text.\n","    \"\"\"      \n","    if to_lower:\n","        txt = txt.lower()\n","    tokens = nltk.tokenize.word_tokenize(txt)\n","    \n","    if remove_stop:\n","        tokens = [tk for tk in tokens if tk not in stop_words]\n","    if do_stem:\n","        tokens = [stemmer.stem(tk) for tk in tokens]\n","    return tokens"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:01:02.615769Z","iopub.status.idle":"2023-02-23T04:01:02.616613Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["MRR@10 0.4187\n"]}],"source":["corpus = list(doc_set.values())\n","# You may experiment with this trying to improve MRR@10\n","remove_stop = True\n","do_stem = True\n","to_lower = True\n","\n","tokenized_corpus = [preprocess_string(doc, remove_stop, do_stem, to_lower) for doc in corpus]\n","\n","bm25 = BM25Okapi(tokenized_corpus)\n","\n","def results_from_query_new(qry_id, bm25):\n","    query = qry_set[qry_id]\n","    rel_docs = []\n","    if qry_id in rel_set:\n","        rel_docs = rel_set[qry_id]\n","    tokenized_query = preprocess_string(query, remove_stop, do_stem, to_lower)\n","    scores = bm25.get_scores(tokenized_query)\n","    most_relevant_documents = np.argsort(-scores)\n","    masked_relevance_results = np.zeros(most_relevant_documents.shape)\n","    masked_relevance_results[rel_docs] = 1\n","    sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n","    return sorted_masked_relevance_results\n","\n","\n","results = [results_from_query_new(qry_id, bm25) for qry_id in list(qry_set.keys())]\n","print('MRR@10 %.4f' % mean_reciprocal_rank(results))"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, a huge improvement (~35%) in MRR@10 doing this 3 preprocessing steps !!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
